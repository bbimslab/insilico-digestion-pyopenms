{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f27a77e2",
   "metadata": {},
   "source": [
    "Code for Generating a peptide list from a fasta | Input - FASTA format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e497506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digestion complete. Peptides written to mcherr77y.csv\n"
     ]
    }
   ],
   "source": [
    "import pyopenms as oms\n",
    "import csv\n",
    "\n",
    "# Specify the local FASTA file\n",
    "fasta_file = \"mcherry.fasta\"  # Replace with your FASTA file name\n",
    "output_csv = \"mcherr76y.csv\"\n",
    "\n",
    "# Parse the FASTA file to extract protein names and sequences\n",
    "def parse_fasta(file_path):\n",
    "    proteins = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        protein_name = \"\"\n",
    "        protein_sequence = \"\"\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\">\"):\n",
    "                if protein_name and protein_sequence:\n",
    "                    proteins.append((protein_name, protein_sequence))\n",
    "                protein_name = line.lstrip(\">\")\n",
    "                protein_sequence = \"\"\n",
    "            else:\n",
    "                protein_sequence += line\n",
    "        if protein_name and protein_sequence:\n",
    "            proteins.append((protein_name, protein_sequence))\n",
    "    return proteins\n",
    "\n",
    "# Load all proteins from the FASTA file\n",
    "proteins = parse_fasta(fasta_file)\n",
    "\n",
    "# Initialize the protease digestion class\n",
    "digestion = oms.ProteaseDigestion()\n",
    "digestion.setMissedCleavages(1)  # Set the number of missed cleavages\n",
    "min_length = 6\n",
    "max_length = 40\n",
    "\n",
    "# Define the oxidation modification for methionine\n",
    "variable_mod_names = [b\"Oxidation (M)\"]\n",
    "variable_modifications = oms.ModifiedPeptideGenerator.getModifications(variable_mod_names)\n",
    "\n",
    "# Prepare to write to the CSV\n",
    "with open(output_csv, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Define output headers\n",
    "    headers = [\"RT\", \"Formula\", \"Name\", \"CCS [M+H]+\", \"CCS [M+Na]+\", \"CCS [M-H]-\",\n",
    "               \"KEGG\", \"CAS\", \"PubChem\", \"ChemSpider\", \"HMDB\", \"BioCyc\",\n",
    "               \"Metlin\", \"LipidMaps\", \"UserID\", \"InChI\"]\n",
    "    writer.writerow(headers)\n",
    "\n",
    "    # Process each protein\n",
    "    for protein_name, protein_sequence in proteins:\n",
    "        protein = oms.AASequence.fromString(protein_sequence)\n",
    "        result = []\n",
    "        digestion.digest(protein, result, min_length, max_length)\n",
    "\n",
    "        # Get peptides and apply modifications\n",
    "        peptides = [peptide.toString() for peptide in result]\n",
    "        modified_peptides = []\n",
    "        for peptide in result:\n",
    "            oms.ModifiedPeptideGenerator.applyVariableModifications(variable_modifications, peptide, 1, modified_peptides, False)\n",
    "\n",
    "        # Combine original and modified peptides\n",
    "        all_peptides = peptides + [peptide.toString() for peptide in modified_peptides]\n",
    "\n",
    "        # Remove sequences with 'X' amino acid\n",
    "        filtered_peptides = [peptide for peptide in all_peptides if 'X' not in peptide]\n",
    "\n",
    "        # Compute molecular formulas and write to CSV\n",
    "        for peptide in filtered_peptides:\n",
    "            name = f\"{protein_name}@{peptide}\"  # Include the protein name\n",
    "            try:\n",
    "                seq_obj = oms.AASequence.fromString(peptide)\n",
    "                molecular_formula = str(seq_obj.getFormula())\n",
    "                # Placeholder values for other fields\n",
    "                retention_time = \"\"\n",
    "                ccs_mh_plus = \"\"\n",
    "                ccs_mna_plus = \"\"\n",
    "                ccs_mh_minus = \"\"\n",
    "                kegg = \"\"\n",
    "                cas = \"\"\n",
    "                pubchem = \"\"\n",
    "                chemspider = \"\"\n",
    "                hmdb = \"\"\n",
    "                biocyc = \"\"\n",
    "                metlin = \"\"\n",
    "                lipidmaps = \"\"\n",
    "                user_id = \"\"\n",
    "                inchi = \"\"\n",
    "            except Exception as e:\n",
    "                molecular_formula = f\"Error: {e}\"\n",
    "\n",
    "            # Write the row\n",
    "            writer.writerow([retention_time, molecular_formula, name, ccs_mh_plus,\n",
    "                             ccs_mna_plus, ccs_mh_minus, kegg, cas, pubchem, chemspider,\n",
    "                             hmdb, biocyc, metlin, lipidmaps, user_id, inchi])\n",
    "\n",
    "print(f\"Digestion complete. Peptides written to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191b56ba",
   "metadata": {},
   "source": [
    "Code for Fetching Protien sequences from uniprot | Input - Proteoscape output - CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7857802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import pyopenms as oms\n",
    "import csv\n",
    "\n",
    "# ----------- Step 1: Read LC-MS/MS CSV and Clean Headers -----------\n",
    "input_csv = \"1.csv\"  # Replace with your actual file path\n",
    "df = pd.read_csv(input_csv, sep=\"\\t\")  # Change sep=\",\" if needed\n",
    "df.columns = df.columns.str.strip()  # Clean column names\n",
    "\n",
    "print(\"Detected columns:\", df.columns.tolist())\n",
    "\n",
    "# ----------- Step 2: Try to Automatically Detect the Protein Group Column -----------\n",
    "protein_col = None\n",
    "for col in df.columns:\n",
    "    if \"protein\" in col.lower() and \"group\" in col.lower():\n",
    "        protein_col = col\n",
    "        break\n",
    "\n",
    "if not protein_col:\n",
    "    raise KeyError(\"❌ Could not find a 'Protein Group Name'-like column in your file.\")\n",
    "\n",
    "print(f\"✅ Using column: {protein_col} to extract UniProt IDs\")\n",
    "\n",
    "# ----------- Step 3: Extract UniProt IDs from the Detected Column -----------\n",
    "def extract_uniprot_id(entry):\n",
    "    match = re.search(r\"\\|([A-Z0-9]+)\\|\", str(entry))\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "df['UniProt_ID'] = df[protein_col].apply(extract_uniprot_id)\n",
    "unique_ids = df['UniProt_ID'].dropna().unique()\n",
    "\n",
    "# ----------- Step 4: Fetch FASTA Sequences from UniProt -----------\n",
    "fasta_file = \"master_proteins.fasta\"\n",
    "base_url = \"https://rest.uniprot.org/uniprotkb/{}.fasta\"\n",
    "\n",
    "with open(fasta_file, \"w\") as fasta_out:\n",
    "    for uid in unique_ids:\n",
    "        response = requests.get(base_url.format(uid))\n",
    "        if response.status_code == 200:\n",
    "            fasta_out.write(response.text)\n",
    "            print(f\"✅ Fetched: {uid}\")\n",
    "        else:\n",
    "            print(f\"❌ Failed to fetch {uid} (status {response.status_code})\")\n",
    "\n",
    "# ----------- Step 5: Parse FASTA File -----------\n",
    "def parse_fasta(file_path):\n",
    "    proteins = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        name = \"\"\n",
    "        seq = \"\"\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\">\"):\n",
    "                if name and seq:\n",
    "                    proteins.append((name, seq))\n",
    "                name = line[1:]\n",
    "                seq = \"\"\n",
    "            else:\n",
    "                seq += line\n",
    "        if name and seq:\n",
    "            proteins.append((name, seq))\n",
    "    return proteins\n",
    "\n",
    "proteins = parse_fasta(fasta_file)\n",
    "\n",
    "# ----------- Step 6: Set Up Digestion Parameters -----------\n",
    "digestion = oms.ProteaseDigestion()\n",
    "digestion.setEnzyme(\"Trypsin\")\n",
    "digestion.setMissedCleavages(1)\n",
    "min_len = 6\n",
    "max_len = 40\n",
    "\n",
    "modifications = oms.ModifiedPeptideGenerator.getModifications([b\"Oxidation (M)\"])\n",
    "\n",
    "# ----------- Step 7: In Silico Digestion + Export to MetaboScape Format -----------\n",
    "output_csv = \"metaboscape_peptides.csv\"\n",
    "with open(output_csv, \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\n",
    "        \"RT\", \"Formula\", \"Name\", \"Mass\", \"CCS [M+H]+\", \"CCS [M+Na]+\", \"CCS [M-H]-\",\n",
    "        \"KEGG\", \"CAS\", \"PubChem\", \"ChemSpider\", \"HMDB\", \"BioCyc\",\n",
    "        \"Metlin\", \"LipidMaps\", \"UserID\", \"InChI\"\n",
    "    ])\n",
    "\n",
    "    for protein_name, protein_seq in proteins:\n",
    "        try:\n",
    "            aa_seq = oms.AASequence.fromString(protein_seq)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error parsing {protein_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        peptides = []\n",
    "        digestion.digest(aa_seq, peptides, min_len, max_len)\n",
    "\n",
    "        modified_peptides = []\n",
    "        for p in peptides:\n",
    "            oms.ModifiedPeptideGenerator.applyVariableModifications(modifications, p, 1, modified_peptides, False)\n",
    "\n",
    "        all_peptides = set([p.toString() for p in peptides] + [p.toString() for p in modified_peptides])\n",
    "        all_peptides = [pep for pep in all_peptides if \"X\" not in pep]\n",
    "\n",
    "        for pep_str in all_peptides:\n",
    "            try:\n",
    "                seq_obj = oms.AASequence.fromString(pep_str)\n",
    "                formula = seq_obj.getFormula().toString()\n",
    "                mass = seq_obj.getMonoWeight()\n",
    "            except Exception as e:\n",
    "                formula = f\"Error: {e}\"\n",
    "                mass = \"\"\n",
    "\n",
    "            name = f\"{protein_name}@{pep_str}\"\n",
    "            writer.writerow([\"\", formula, name, mass, \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"])\n",
    "\n",
    "print(f\"\\n🎉 Digestion complete. Peptides saved to: {output_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ba5da1",
   "metadata": {},
   "source": [
    "Split peptide list into 50000 chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a822e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import pyopenms as oms\n",
    "import csv\n",
    "import math\n",
    "\n",
    "# ----------- Step 1: Read LC-MS/MS CSV and Clean Headers -----------\n",
    "input_csv = \"1.csv\"\n",
    "df = pd.read_csv(input_csv, sep=\"\\t\")\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "print(\"Detected columns:\", df.columns.tolist())\n",
    "\n",
    "# ----------- Step 2: Detect the Protein Group Column -----------\n",
    "protein_col = None\n",
    "for col in df.columns:\n",
    "    if \"protein\" in col.lower() and \"group\" in col.lower():\n",
    "        protein_col = col\n",
    "        break\n",
    "\n",
    "if not protein_col:\n",
    "    raise KeyError(\" Could not find a 'Protein Group Name'-like column in your file.\")\n",
    "print(f\" Using column: {protein_col} to extract UniProt IDs\")\n",
    "\n",
    "# ----------- Step 3: Extract UniProt IDs -----------\n",
    "def extract_uniprot_id(entry):\n",
    "    match = re.search(r\"\\|([A-Z0-9]+)\\|\", str(entry))\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "df['UniProt_ID'] = df[protein_col].apply(extract_uniprot_id)\n",
    "unique_ids = df['UniProt_ID'].dropna().unique()\n",
    "\n",
    "# ----------- Step 4: Fetch FASTA Sequences from UniProt -----------\n",
    "fasta_file = \"master_proteins.fasta\"\n",
    "base_url = \"https://rest.uniprot.org/uniprotkb/{}.fasta\"\n",
    "\n",
    "with open(fasta_file, \"w\") as fasta_out:\n",
    "    for uid in unique_ids:\n",
    "        response = requests.get(base_url.format(uid))\n",
    "        if response.status_code == 200:\n",
    "            fasta_out.write(response.text)\n",
    "            print(f\" Fetched: {uid}\")\n",
    "        else:\n",
    "            print(f\" Failed to fetch {uid} (status {response.status_code})\")\n",
    "\n",
    "# ----------- Step 5: Parse FASTA File -----------\n",
    "def parse_fasta(file_path):\n",
    "    proteins = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        name, seq = \"\", \"\"\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\">\"):\n",
    "                if name and seq:\n",
    "                    proteins.append((name, seq))\n",
    "                name = line[1:]\n",
    "                seq = \"\"\n",
    "            else:\n",
    "                seq += line\n",
    "        if name and seq:\n",
    "            proteins.append((name, seq))\n",
    "    return proteins\n",
    "\n",
    "proteins = parse_fasta(fasta_file)\n",
    "\n",
    "# ----------- Step 6: Setup Digestion Parameters -----------\n",
    "digestion = oms.ProteaseDigestion()\n",
    "digestion.setEnzyme(\"Trypsin\")\n",
    "digestion.setMissedCleavages(1)\n",
    "min_len = 6\n",
    "max_len = 40\n",
    "\n",
    "modifications = oms.ModifiedPeptideGenerator.getModifications([b\"Oxidation (M)\"])\n",
    "\n",
    "# ----------- Step 7: Digest and Buffer All Output Rows -----------\n",
    "all_rows = []\n",
    "\n",
    "for protein_name, protein_seq in proteins:\n",
    "    try:\n",
    "        aa_seq = oms.AASequence.fromString(protein_seq)\n",
    "    except Exception as e:\n",
    "        print(f\" Error parsing {protein_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    peptides = []\n",
    "    digestion.digest(aa_seq, peptides, min_len, max_len)\n",
    "\n",
    "    modified_peptides = []\n",
    "    for p in peptides:\n",
    "        oms.ModifiedPeptideGenerator.applyVariableModifications(modifications, p, 1, modified_peptides, False)\n",
    "\n",
    "    all_peptides = set([p.toString() for p in peptides] + [p.toString() for p in modified_peptides])\n",
    "    all_peptides = [pep for pep in all_peptides if \"X\" not in pep]\n",
    "\n",
    "    for pep_str in all_peptides:\n",
    "        try:\n",
    "            seq_obj = oms.AASequence.fromString(pep_str)\n",
    "            formula = seq_obj.getFormula().toString()\n",
    "            mass = seq_obj.getMonoWeight()\n",
    "        except Exception as e:\n",
    "            formula = f\"Error: {e}\"\n",
    "            mass = \"\"\n",
    "\n",
    "        name = f\"{protein_name}@{pep_str}\"\n",
    "        row = [\"\", formula, name, mass, \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"]\n",
    "        all_rows.append(row)\n",
    "\n",
    "# ----------- Step 8: Write into Chunks of 10,000 for MetaboScape -----------\n",
    "chunk_size = 50000\n",
    "total_parts = math.ceil(len(all_rows) / chunk_size)\n",
    "output_prefix = \"metaboscape_peptides_part\"\n",
    "\n",
    "print(f\" Writing {len(all_rows)} peptides into {total_parts} MetaboScape-compatible files...\")\n",
    "\n",
    "for i in range(total_parts):\n",
    "    chunk = all_rows[i * chunk_size:(i + 1) * chunk_size]\n",
    "    filename = f\"{output_prefix}{i + 1}.csv\"\n",
    "    with open(filename, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            \"RT\", \"Formula\", \"Name\", \"Mass\", \"CCS [M+H]+\", \"CCS [M+Na]+\", \"CCS [M-H]-\",\n",
    "            \"KEGG\", \"CAS\", \"PubChem\", \"ChemSpider\", \"HMDB\", \"BioCyc\",\n",
    "            \"Metlin\", \"LipidMaps\", \"UserID\", \"InChI\"\n",
    "        ])\n",
    "        writer.writerows(chunk)\n",
    "    print(f\" {filename} saved with {len(chunk)} rows\")\n",
    "\n",
    "print(\"\\n Digestion complete. All peptide chunks saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
